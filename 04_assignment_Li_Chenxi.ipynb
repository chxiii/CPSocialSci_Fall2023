{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9d41096b-4881-49ee-ac7a-a497ba41bc92",
      "metadata": {},
      "source": [
        "# POP77001 Assignment 4: Data Wrangling and Classes in Python\n",
        "\n",
        "## Before Submission\n",
        "\n",
        "-   Do not use external libraries unless explicitly specified.\n",
        "-   Make sure that you can run all cells without errors.\n",
        "-   You can do it by clicking `Kernel`, `Restart & Run All` in the menu\n",
        "    above.\n",
        "-   Make sure that you save the output by pressing Command+S / CTRL+S.\n",
        "-   Rename the file from `04_assignment.ipynb` to\n",
        "    `04_assignment_studentnumber_firstname_lastname.ipynb`.\n",
        "-   Use Firefox browser for submitting your Jupyter notebook on\n",
        "    Blackboard.\n",
        "\n",
        "## Exercise 1: Data Transformation\n",
        "\n",
        "For exercises 1-3 we will be working with the\n",
        "[Titanic](https://github.com/pandas-dev/pandas/blob/master/doc/data/titanic.csv)\n",
        "dataset. It contains the list of passengers on Titanic with their\n",
        "sociodemographic characteristics, names and ticket details. First,\n",
        "create two new columns, called ‘Last Name’ and ‘First Name’ containing\n",
        "last name and first name of each passenger. Next, calculate the\n",
        "frequencies of passengers’ last names. What were the 3 most common last\n",
        "names of passengers on the ship?\n",
        "\n",
        "External libraries:\n",
        "\n",
        "-   `numpy`, `pandas`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "29edfcf7",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "4d6fe587",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [],
      "source": [
        "titanic = pd.read_csv(\"https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/titanic.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "5e89e708",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Binned Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>[18.0, 25.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "      <td>[35.0, 150.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>[25.0, 35.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "      <td>[35.0, 150.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>[35.0, 150.0)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                           Allen, Mr. William Henry    male  35.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked     Binned Age  \n",
              "0      0         A/5 21171   7.2500   NaN        S   [18.0, 25.0)  \n",
              "1      0          PC 17599  71.2833   C85        C  [35.0, 150.0)  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S   [25.0, 35.0)  \n",
              "3      0            113803  53.1000  C123        S  [35.0, 150.0)  \n",
              "4      0            373450   8.0500   NaN        S  [35.0, 150.0)  "
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "titanic.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "id": "cb09c5f8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Last Name                First Name\n",
            "0       Braund               Owen Harris\n",
            "1      Cumings              John Bradley\n",
            "2    Heikkinen                     Laina\n",
            "3     Futrelle             Jacques Heath\n",
            "4        Allen             William Henry\n",
            "..         ...                       ...\n",
            "886   Montvila                    Juozas\n",
            "887     Graham            Margaret Edith\n",
            "888   Johnston  Catherine Helen \"Carrie\"\n",
            "889       Behr               Karl Howell\n",
            "890     Dooley                   Patrick\n",
            "\n",
            "[891 rows x 2 columns]\n",
            "The last names frequencies is: \n",
            "\n",
            "Andersson    9\n",
            "Sage         7\n",
            "Panula       6\n",
            "Skoog        6\n",
            "Carter       6\n",
            "            ..\n",
            "Hanna        1\n",
            "Lewy         1\n",
            "Mineff       1\n",
            "Haas         1\n",
            "Dooley       1\n",
            "Name: Last Name, Length: 667, dtype: int64\n",
            "The 3 most common last name is: \n",
            "\n",
            "Andersson    9\n",
            "Sage         7\n",
            "Panula       6\n",
            "Name: Last Name, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Exercise 1:\n",
        "\n",
        "# Your code goes here\n",
        "\n",
        "####### Calculate the frequencies of passenger's last names #######\n",
        "\n",
        "##### Split \"Name\" as \"First Name\" and \"Last Name\" #####\n",
        "\n",
        "# Extract Last Name\n",
        "titanic[\"Last Name\"] = titanic[\"Name\"].apply(lambda x: x.split(\",\")[0])\n",
        "\n",
        "# Extract First Name and Middle Name\n",
        "temp = titanic[\"Name\"].apply(lambda x: x.split(\",\")[1].split(\".\")[1].strip())\n",
        "\n",
        "# Extract First Name without Middle Name\n",
        "titanic[\"First Name\"] = temp.apply(lambda x: x.split(\"(\")[0].strip() if \"(\" in x else x)\n",
        "\n",
        "# Print the results\n",
        "print(titanic[[\"Last Name\", \"First Name\"]])\n",
        "\n",
        "# Calculate last names frequencies\n",
        "last_name_frequencies = titanic[\"Last Name\"].value_counts()\n",
        "\n",
        "# Print the answers\n",
        "print(\"The last names frequencies is: \\n\")\n",
        "print(last_name_frequencies)\n",
        "\n",
        "####### 3 Most Common Last Name #######\n",
        "\n",
        "# Because the value count has ordered the value\n",
        "# So top 3 last name is the top 3 in last_name_frequencies\n",
        "top_3_last_name = last_name_frequencies.head(3)\n",
        "\n",
        "# Print the answers\n",
        "print(\"The 3 most common last name is: \\n\")\n",
        "print(top_3_last_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5530f98d-9624-445c-846a-6249d66b7f89",
      "metadata": {},
      "source": [
        "## Exercise 2: Binning\n",
        "\n",
        "When analyzing a continuous variable we often want to break it up into\n",
        "discrete categories (bins). For example, age might be considered as a\n",
        "categorical variable with discrete categories of ‘18-25’, ‘26-35’, etc.\n",
        "Implement a function that takes a dataframe, variable name and cutoff\n",
        "points (e.g. 18, 25, 35, etc.) as inputs and returns a dataframe with a\n",
        "single column, which is binned into desired categories. Run this\n",
        "function on the age column of Titanic dataset. What percentage of\n",
        "passengers falls into each of the age bins?\n",
        "\n",
        "Tip: You can use `pandas.cut()` method internally.\n",
        "\n",
        "Function specification:\n",
        "\n",
        "Function takes 3 arguments:\n",
        "\n",
        "-   `df` - pandas data frame\n",
        "-   `col` - the name of column to be binned\n",
        "-   `cutoffs` - a sequence of cuttoff value to be used for binning\n",
        "\n",
        "Function returns 1 object:\n",
        "\n",
        "-   `binned_df` - pandas data frame with the selected column binned\n",
        "    according to the specification\n",
        "\n",
        "External libraries:\n",
        "\n",
        "-   `numpy`, `pandas`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "8a833967",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The percantage of age bin is: \n",
            "[35.0, 150.0)    32.913165\n",
            "[25.0, 35.0)     28.151261\n",
            "[18.0, 25.0)     23.109244\n",
            "[0.0, 18.0)      15.826331\n",
            "Name: Age, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Exercise 2:\n",
        "\n",
        "# Your code goes here\n",
        "\n",
        "####### Check the range of the variable \"Age\" #######\n",
        "\n",
        "max_age = titanic[\"Age\"].max() # The max age is 80\n",
        "min_age = titanic[\"Age\"].min() # The min age is 0.42\n",
        "\n",
        "####### Create a function with 3 arguments #######\n",
        "def binning(df, col, cutoffs):\n",
        "    \"\"\"\n",
        "    This function is used to binning data.\n",
        "\n",
        "    Parameters:\n",
        "\n",
        "    - \"df\": pandas data frame\n",
        "    - \"col\": the name of column to be binned\n",
        "    - \"cutoffs\": a sequence of cuttoff value to be used for binning\n",
        "    \"\"\"\n",
        "\n",
        "    ##### Create group for age #####\n",
        "\n",
        "    # Because the minimun age is 0.42, the maximise age is 80,\n",
        "    # So I choose 0 - 150 as the range of groups\n",
        "    groups = [float(0)] + cutoffs + [float(150)]\n",
        "    \n",
        "    # Create a new column of categarical age\n",
        "    binned_df = pd.cut(df[col], bins = groups, right=False)\n",
        "    return binned_df\n",
        "\n",
        "# Create the cutoff points about age\n",
        "age_cutoffs = [18, 25, 35]\n",
        "\n",
        "# Use the function to bin age\n",
        "ex2_titanic = binning(titanic, \"Age\", age_cutoffs)\n",
        "titanic[\"Binned Age\"] = ex2_titanic.astype(str) # Prepare for the next excise's analysis\n",
        "\n",
        "# Calcualte the percentage of each bin\n",
        "bin_age_perc = ex2_titanic.value_counts(normalize=True) * 100\n",
        "\n",
        "# Print the results\n",
        "print(\"The percantage of age bin is: \")\n",
        "print(bin_age_perc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6339660c-a2c5-41e2-9ff2-3aac6adf494c",
      "metadata": {},
      "source": [
        "## Exercise 3: Pattern Detection\n",
        "\n",
        "Let us consider the column `Survived`, which contains a binary indicator\n",
        "of whether a given passenger survived the sinking of Titanic. What\n",
        "factors might explain the survival of some passengers but not others?\n",
        "How would you investigate these relationships? Describe your hypotheses\n",
        "and descriptive analyses that can help answering these questions.\n",
        "Perform the outlined descriptive analyses on the dataset.\n",
        "\n",
        "External libraries:\n",
        "\n",
        "-   `numpy`, `pandas`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "07a01ada",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- The survival rate of titanic is\n",
            " 38.38 %.\n",
            "- The survaval rate group by  Pclass is\n",
            " Pclass\n",
            "1    62.96\n",
            "2    47.28\n",
            "3    24.24\n",
            "Name: Survived, dtype: float64 %.\n",
            "- The survaval rate group by  Sex is\n",
            " Sex\n",
            "female    74.20\n",
            "male      18.89\n",
            "Name: Survived, dtype: float64 %.\n",
            "- The survaval rate group by  Binned Age is\n",
            " Binned Age\n",
            "[0.0, 18.0)      53.98\n",
            "[18.0, 25.0)     34.55\n",
            "[25.0, 35.0)     38.81\n",
            "[35.0, 150.0)    40.00\n",
            "nan              29.38\n",
            "Name: Survived, dtype: float64 %.\n",
            "- The survaval rate group by  SibSp is\n",
            " SibSp\n",
            "0    34.54\n",
            "1    53.59\n",
            "2    46.43\n",
            "3    25.00\n",
            "4    16.67\n",
            "5     0.00\n",
            "8     0.00\n",
            "Name: Survived, dtype: float64 %.\n",
            "- The survaval rate group by  Parch is\n",
            " Parch\n",
            "0    34.37\n",
            "1    55.08\n",
            "2    50.00\n",
            "3    60.00\n",
            "4     0.00\n",
            "5    20.00\n",
            "6     0.00\n",
            "Name: Survived, dtype: float64 %.\n",
            "\n",
            "- The crosstable results are:\n",
            " [Pclass      1   2    3\n",
            "Survived              \n",
            "0          80  97  372\n",
            "1         136  87  119, Sex       female  male\n",
            "Survived              \n",
            "0             81   468\n",
            "1            233   109, Binned Age  [0.0, 18.0)  [18.0, 25.0)  [25.0, 35.0)  [35.0, 150.0)  nan\n",
            "Survived                                                               \n",
            "0                    52           108           123            141  125\n",
            "1                    61            57            78             94   52, SibSp       0    1   2   3   4  5  8\n",
            "Survived                            \n",
            "0         398   97  15  12  15  5  7\n",
            "1         210  112  13   4   3  0  0, Parch       0   1   2  3  4  5  6\n",
            "Survived                         \n",
            "0         445  53  40  2  4  4  1\n",
            "1         233  65  40  3  0  1  0]\n",
            "\n",
            "- The chi square value between Survived and categorical varialbs is: (102.88898875696057, 2)\n",
            "\n",
            "- The chi square value between Survived and categorical varialbs is: (263.05057407065567, 1)\n",
            "\n",
            "- The chi square value between Survived and categorical varialbs is: (18.99685054264794, 4)\n",
            "\n",
            "- The chi square value between Survived and categorical varialbs is: (37.27179291520431, 6)\n",
            "\n",
            "- The chi square value between Survived and categorical varialbs is: (27.925784060236165, 6)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\\nFinally, we can compare the chi2 value with limitation chi2 value accroding to the degree of freedom to decide wether or not we accept the null hypothesis.\\n'"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Exercise 3:\n",
        "\n",
        "# Your text and code go here\n",
        "\n",
        "\"\"\"\n",
        "- Perform the outlined descriptvie analyses on the database.\n",
        "\n",
        "\"\"\" \n",
        "survival_rate = titanic[\"Survived\"].mean() \n",
        "print(\"- The survival rate of titanic is\\n\", round(survival_rate * 100, 2), \"%.\")\n",
        "\n",
        "\"\"\" \n",
        "- What factors might explain the survival of some passengers but not others?\n",
        "\n",
        "I think Pclass, Sex, Binned Age, SibSp, Parch may explain the survival rate.\n",
        "\n",
        "- How would you investigate these relationships? \n",
        "\n",
        "Firstly, I will find the distribution of survival rate group by these categoricals.\n",
        "To find the distribution, I will use crosstable to describe.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "cate_var = [\"Pclass\", \"Sex\", \"Binned Age\", \"SibSp\", \"Parch\"]\n",
        "cross_data = []\n",
        "\n",
        "for i in cate_var:\n",
        "    print(\n",
        "        \"- The survaval rate group by \", i, \"is\\n\", \n",
        "        round(titanic.groupby(i)[\"Survived\"].mean() * 100, 2), \"%.\")\n",
        "    cross_data.append(pd.crosstab(titanic[\"Survived\"], titanic[i]))\n",
        "\n",
        "print(\"\\n- The crosstable results are:\\n\", cross_data)\n",
        "\"\"\"\n",
        "\n",
        "Secondly, because Survived is a nominal variable, \n",
        "and other variables can also be regarded as categorical variables,\n",
        "So I choose to make Chi-square test.\n",
        "\n",
        "- Descripe my hypothesis\n",
        "\n",
        "H0: Survived is not related to Pclass / Sex / Binned Age / SibSp / Parch\n",
        "H1: Survived is related to Pclass / Sex / Binned Age / SibSp / Parch\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def chi2_test(cross_data):\n",
        "    \"\"\"\n",
        "    This function is used to calculate chi2 square by hand.\n",
        "\n",
        "    Parameters:\n",
        "\n",
        "    - cross_data: a crosstable data.\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate the rows and cols total\n",
        "    row_totals = cross_data.sum(axis=1).values\n",
        "    col_totals = cross_data.sum(axis=0).values\n",
        "    total = cross_data.sum().sum()\n",
        "\n",
        "    # Calculate the expected value\n",
        "    expected = []\n",
        "    for i in range(cross_data.shape[0]):\n",
        "        row_expected = []\n",
        "        for j in range(cross_data.shape[1]):\n",
        "            row_expected.append((row_totals[i] * col_totals[j]) / total)\n",
        "        expected.append(row_expected)\n",
        "    \n",
        "    expected = pd.DataFrame(expected, index=cross_data.index, columns=cross_data.columns)\n",
        "\n",
        "    # Calculate the chi^2 value\n",
        "    chi2_value = ((cross_data - expected)**2 / expected).sum().sum()\n",
        "\n",
        "    # Calculate the degree of freedom\n",
        "    df = (cross_data.shape[0] - 1) * (cross_data.shape[1] - 1)\n",
        "\n",
        "    return chi2_value, df\n",
        "\n",
        "\n",
        "for i in cross_data:\n",
        "    print(\"\\n- The chi square value between Survived and categorical varialbs is:\", chi2_test(i))\n",
        "\n",
        "\"\"\"\n",
        "Finally, we can compare the chi2 value with limitation chi2 value accroding to the degree of freedom to decide wether or not we accept the null hypothesis.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9453b145-cd2d-45bc-870e-55ea054ba11f",
      "metadata": {},
      "source": [
        "## Exercise 4: Classes and Methods\n",
        "\n",
        "Classes are a common way of organizing code for statistical models. As a\n",
        "programming mechanism, classes allow us to group data and functions\n",
        "together, which is precisely what we usually want to do when\n",
        "implementing a statistical model. Below you can see a skeleton of a base\n",
        "class for statistical models. Specify private methods `__init__()` for\n",
        "creating an object of type `StatisticalModel` and `__str__()` for\n",
        "printing a string representation of the model. As you will be relying on\n",
        "this class definition in Exercise 5, you may wish to take a look at it\n",
        "as well before implementing the methods.\n",
        "\n",
        "Methods specification:\n",
        "\n",
        "-   `__init__()` - initialize the `StatisticalModel` object\n",
        "-   `__str__()` - return a string representation of the model of the\n",
        "    form below (let’s try to make it roughly consistent with R):\n",
        "\n",
        "<!-- -->\n",
        "\n",
        "    Model:\n",
        "    y ~ x1 + x2 + ... + xn\n",
        "\n",
        "    Coefficients:\n",
        "    [None, None]\n",
        "\n",
        "External libraries:\n",
        "\n",
        "-   None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "id": "5a6eb25a",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [],
      "source": [
        "class StatisticalModel:\n",
        "    \"\"\"Base class for Statistical Models\"\"\"\n",
        "    def __init__(self, x, y):\n",
        "        \"\"\"\n",
        "        Initialize the StatisticalModel.\n",
        "\n",
        "        Parameters:\n",
        "        - y: The dependent variable (DV) for the model.\n",
        "        - x: The independent variables (IVs) for the model.\n",
        "        \"\"\"\n",
        "        pass\n",
        "    def fit(self, data):\n",
        "        \"\"\"\n",
        "        Fit the statistical model using the provided data.\n",
        "\n",
        "        Parameters:\n",
        "        - data: The training dataset containing both DV and IVs.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "    def predict(self, data):\n",
        "        \"\"\"\n",
        "        Make predictions using the fitted model.\n",
        "\n",
        "        Parameters:\n",
        "        - data: The dataset for which predictions are to be made.\n",
        "\n",
        "        Returns:\n",
        "        - predictions: The predicted values.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "    def __str__(self):\n",
        "        \"\"\"Return a string representation of the model.\"\"\"\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "id": "3d9ac94e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model:\n",
            "y ~ x1 + x2 + ... + xn\n",
            "\n",
            "Coefficients:\n",
            "[None, None, None, None, None]\n"
          ]
        }
      ],
      "source": [
        "# Exercise 4:\n",
        "\n",
        "# Your text and code go here\n",
        "\n",
        "class StatisticalModel:\n",
        "    \"\"\"Base class for Statistical Models\"\"\"\n",
        "    def __init__(self, x, y):\n",
        "        \"\"\"\n",
        "        Initialize the StatisticalModel.\n",
        "\n",
        "        Parameters:\n",
        "        - x (str): The dependent variable (DV) for the model.\n",
        "        - y (list): The independent variables (IVs) for the model.\n",
        "        \"\"\"\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.coefficients = [None] * (len(y) + 1)\n",
        "\n",
        "    def fit(self, data):\n",
        "        \"\"\"\n",
        "        Fit the statistical model using the provided data.\n",
        "\n",
        "        Parameters:\n",
        "        - data: The training dataset containing both DV and IVs.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def predict(self, data):\n",
        "        \"\"\"\n",
        "        Make predictions using the fitted model.\n",
        "\n",
        "        Parameters:\n",
        "        - data: The dataset for which predictions are to be made.\n",
        "\n",
        "        Returns:\n",
        "        - predictions: The predicted values.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"Return a string representation of the model.\"\"\"\n",
        "        model_str = f\"Model:\\n{self.x} ~ {' + '.join(self.y)}\\n\\n\"\n",
        "        model_str += \"Coefficients:\\n\"\n",
        "        model_str += str(self.coefficients)\n",
        "        return model_str\n",
        "\n",
        "# Print an example output\n",
        "model = StatisticalModel(\"y\", [\"x1\", \"x2\", \"...\",\"xn\"])\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "437677d9-2fdc-441a-8391-0b862614186d",
      "metadata": {},
      "source": [
        "## Exercise 5: Inheritance\n",
        "\n",
        "[Linear regression](https://en.wikipedia.org/wiki/Linear_regression) is\n",
        "a fundamental statistical model. It is used to study the relationship\n",
        "between a dependent variable `y` and one or more explanatory variables\n",
        "`x`. Below you can find functions `fit_lm()` and `predict_lm()` that\n",
        "estimate the coefficients of a linear regression model and predict the\n",
        "dependent variable based on those estimates and the independent\n",
        "variable. Write a class `LinearModel` that inherits from the base class\n",
        "`StatisticalModel` and implements `fit()` and `predict()` methods. You\n",
        "can use the `fit_lm()` and `predict_lm()` functions as a reference for\n",
        "the implementation. Create an object of type `LinearModel` and fit a\n",
        "model to the `x` and `y` arrays below. Then use the fitted model to\n",
        "predict the dependent variable for the `new_x` object. Compare the\n",
        "results with the results of `fit_lm()` and `predict_lm()`.\n",
        "\n",
        "Method specification:\n",
        "\n",
        "Method `fit()` takes 0 arguments (in addition to `self`).\n",
        "\n",
        "Method `predict()` takes 1 argument (in addition to `self`):\n",
        "\n",
        "-   `new_x` - NumPy matrix representing the independent variable(s) for\n",
        "    which predictions are to be made.\n",
        "\n",
        "Example input → output:\n",
        "\n",
        "-   for `fit()` - $[1, 2, 3]$ and $[4, 5, 6]$ → $np.array([3., 1.])$\n",
        "-   for `predict()` - $[3, 1]$ and $[1, 2, 3]$ →\n",
        "    $np.array([4., 5., 6.])$\n",
        "\n",
        "External libraries:\n",
        "\n",
        "-   `numpy`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "d41787d1",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "ca0a8e25",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [],
      "source": [
        "def fit_lm(x, y):\n",
        "    \"\"\"\n",
        "    Fit a linear regression model.\n",
        "\n",
        "    Parameters:\n",
        "    - x: NumPy matrix representing the independent variable.\n",
        "    - y: NumPy matrix representing the dependent variable.\n",
        "\n",
        "    Returns:\n",
        "    - betas: NumPy matrix containing the coefficients of the linear regression model.\n",
        "    \"\"\"\n",
        "    # Ensure x and y are NumPy matrices\n",
        "    x = np.array(x)\n",
        "    y = np.array(y)\n",
        "    \n",
        "    # Append a column of ones to x (for the intercept)\n",
        "    x = np.c_[np.ones(x.shape[0]), x]\n",
        "    \n",
        "    # Calculate the coefficients (@ is matrix multiplication)\n",
        "    betas = np.linalg.inv(x.T @ x) @ x.T @ y\n",
        "    \n",
        "    return betas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "e69cd57e",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [],
      "source": [
        "def predict_lm(betas, new_x):\n",
        "    \"\"\"\n",
        "    Predict the dependent variable using a linear regression model.\n",
        "\n",
        "    Parameters:\n",
        "    - betas: NumPy matrix representing the coefficients of the linear regression model.\n",
        "    - new_x: NumPy matrix representing new data for prediction.\n",
        "\n",
        "    Returns:\n",
        "    - pred_y: NumPy matrix containing the predicted values.\n",
        "    \"\"\"\n",
        "    # Ensure coefficients and new_x are NumPy matrices\n",
        "    betas = np.array(betas)\n",
        "    new_x = np.array(new_x)\n",
        "\n",
        "    # Add a column of ones to new_data for the intercept term\n",
        "    new_x = np.c_[np.ones(new_x.shape[0]), new_x]\n",
        "\n",
        "    # Use the model coefficients to make predictions\n",
        "    pred_y = new_x @ betas\n",
        "\n",
        "    return pred_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "b31a3ef5",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[3.57082489],\n",
              "       [0.33611126]])"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a random number generator (RNG) object\n",
        "rng = np.random.default_rng(seed = 2023)\n",
        "# Draw 100 random numbers from a standard normal distribution\n",
        "x = rng.normal(size = (100, 1))\n",
        "y = 3.5 + 0.3 * x + rng.normal(size = (100, 1))\n",
        "lm_fit = fit_lm(x, y)\n",
        "lm_fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "c1b02648",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[3.67396296],\n",
              "       [3.27594621],\n",
              "       [3.37225365],\n",
              "       [4.13645082],\n",
              "       [4.22169529],\n",
              "       [3.88731366],\n",
              "       [3.23246086],\n",
              "       [4.06279777],\n",
              "       [4.18335601],\n",
              "       [3.37346711]])"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_x = rng.normal(size = (10, 1))\n",
        "y_hat = predict_lm(lm_fit, new_x)\n",
        "y_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "id": "7e020c36",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coefficients:  [[3.]\n",
            " [1.]]\n",
            "Predictions:  [[4.]\n",
            " [5.]\n",
            " [6.]]\n"
          ]
        }
      ],
      "source": [
        "# Exercise 5:\n",
        "\n",
        "# Your text and code go here\n",
        "\n",
        "class LinearModel(StatisticalModel):\n",
        "    \"\"\"Linear Regression Model\"\"\"\n",
        "\n",
        "    def fit(self):\n",
        "        \"\"\"\n",
        "        Fit the linear regression model using the provided data.\n",
        "\n",
        "        Returns:\n",
        "        - coefficients: The estimated coefficients for the model.\n",
        "        \"\"\"\n",
        "        # Assuming x is a matrix where the first column is a column of ones (for the intercept)\n",
        "        x_matrix = np.column_stack((np.ones(len(self.x)), self.x))\n",
        "        coefficients = np.linalg.inv(x_matrix.T @ x_matrix) @ x_matrix.T @ self.y\n",
        "        self.coefficients = coefficients\n",
        "        return coefficients\n",
        "\n",
        "    def predict(self, new_x):\n",
        "        \"\"\"\n",
        "        Make predictions using the fitted linear regression model.\n",
        "\n",
        "        Parameters:\n",
        "        - new_x: NumPy matrix representing the independent variable(s) for which predictions are to be made.\n",
        "\n",
        "        Returns:\n",
        "        - predictions: The predicted values.\n",
        "        \"\"\"\n",
        "        # Assuming new_x is a matrix where the first column is a column of ones (for the intercept)\n",
        "        new_x_matrix = np.column_stack((np.ones(len(new_x)), new_x))\n",
        "        predictions = new_x_matrix @ self.coefficients\n",
        "        return predictions\n",
        "\n",
        "# Example output:\n",
        "x = np.array([[1], [2], [3]])\n",
        "y = np.array([[4], [5], [6]])\n",
        "\n",
        "betas = np.array([[3], [1]])\n",
        "new_x = np.array([[1], [2], [3]])\n",
        "\n",
        "# Create LinearModel object\n",
        "linear_model = LinearModel(x, y)\n",
        "\n",
        "# Fit the model\n",
        "coefficients = linear_model.fit()\n",
        "print(\"Coefficients: \", coefficients)\n",
        "\n",
        "# Predict using the fitted model\n",
        "predictions = linear_model.predict(new_x)\n",
        "print(\"Predictions: \", predictions)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
